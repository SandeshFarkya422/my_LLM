{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0604e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b43b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device in use: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85fe367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.rev_vocab = {}\n",
    "        self.token_count = 0\n",
    "\n",
    "    def bulid_vocab(self, texxts,min_freq=2):\n",
    "        all_chars=[]\n",
    "        for text in texts:\n",
    "            cleaned_text =re.sub(r'[^a-zA-Z0-9\\s]', '', text)     \n",
    "            all_chars.extend(list(cleaned_text))\n",
    "\n",
    "        char_counts = Counter(all_chars)\n",
    "\n",
    "        # Add sppecial tokens\n",
    "        self.vocab= {\n",
    "            '<pad>': 0,\n",
    "            '<unk>': 1,\n",
    "            '<sos>': 2,\n",
    "            '<eos>': 3\n",
    "        }\n",
    "        self.inx_to_token = {0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'}\n",
    "\n",
    "        indx=4\n",
    "        for char,count in char_counts.items():\n",
    "            if count >= min_freq:\n",
    "                self.vocab[char] = indx\n",
    "                self.inx_to_token[indx] = char\n",
    "                indx += 1    \n",
    "            \n",
    "            def encode(self,token):    \n",
    "                tokens =[self.vocab['<bos>']]\n",
    "                for char in text:\n",
    "                    tokens.append(self.vocab.get(char, self.vocab['<unk>']))\n",
    "                tokens.append(self.vocab['<eos>'])\n",
    "                return tokens\n",
    "            \n",
    "            def decode(self,token_ids):\n",
    "                text = \"\"\n",
    "                for token_id in token_ids:\n",
    "                    if token_id in [self.vocab['<pad>'],self.vocab['<bps>'],self.vocab['<eos>']]:\n",
    "                        continue\n",
    "                    elif token_id == self.vocab['<unk>']:\n",
    "                        text += '?'\n",
    "                    else:\n",
    "                        text += self.inx_to_token(token_id, '')\n",
    "                return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a8373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9746d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
